#!/usr/bin/env python3
"""
Actual Data Collection Test
Demonstrates real scraping capabilities as described in ENHANCED_HEAD_TO_HEAD_IMPLEMENTATION.md
and FOUR_WAY_COMPARISON_GUIDE.md by collecting actual data from G2.com comparison pages.
"""

import asyncio
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import sys
import os

# Add the current directory to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import importlib.util

# Load the module from the file
spec = importlib.util.spec_from_file_location("chimera_ultimate", "chimera-ultimate.py")
chimera_ultimate = importlib.util.module_from_spec(spec)
sys.modules["chimera_ultimate"] = chimera_ultimate
spec.loader.exec_module(chimera_ultimate)

from chimera_ultimate import ChimeraUltimate

class ActualDataCollectionTester:
    """Test suite for actual data collection capabilities"""
    
    def __init__(self):
        self.chimera = ChimeraUltimate()
        self.collected_data = {
            "timestamp": datetime.now().isoformat(),
            "head_to_head_comparisons": [],
            "four_way_comparisons": [],
            "ai_summaries": [],
            "competitive_insights": [],
            "summary": {}
        }
        
    async def run_complete_data_collection(self):
        """Run complete data collection to prove scraping capabilities"""
        print("üöÄ Starting Actual Data Collection Test")
        print("=" * 80)
        print("üéØ This test will collect REAL data from G2.com comparison pages")
        print("üìä Proving scraping capabilities as described in implementation guides")
        print("=" * 80)
        
        # Test URLs for data collection
        head_to_head_urls = [
            "https://www.g2.com/compare/tableau-vs-microsoft-power-bi",
            "https://www.g2.com/compare/salesforce-vs-hubspot",
            "https://www.g2.com/compare/zoom-vs-microsoft-teams"
        ]
        
        four_way_urls = [
            "https://www.g2.com/compare/microsoft-microsoft-power-bi-vs-qlik-sense-vs-tableau-vs-domo",
            "https://www.g2.com/compare/salesforce-vs-hubspot-vs-pipedrive-vs-zoho-crm"
        ]
        
        # Phase 1: Head-to-Head Comparison Data Collection
        print("\nüîÑ PHASE 1: Head-to-Head Comparison Data Collection")
        print("-" * 60)
        
        for i, url in enumerate(head_to_head_urls, 1):
            print(f"\nüìä Collecting data from comparison {i}/{len(head_to_head_urls)}: {url}")
            try:
                comparison_data = await self.collect_head_to_head_data(url)
                self.collected_data["head_to_head_comparisons"].append(comparison_data)
                
                print(f"   ‚úÖ Success: {comparison_data.get('success', False)}")
                print(f"   üìà Data Quality: {comparison_data.get('data_quality_score', 0):.1f}%")
                print(f"   ü§ñ AI Summaries: {comparison_data.get('ai_summaries_found', 0)}")
                print(f"   üìù Data Points: {comparison_data.get('total_data_points', 0)}")
                
            except Exception as e:
                print(f"   ‚ùå Error: {str(e)}")
                self.collected_data["head_to_head_comparisons"].append({
                    "url": url,
                    "success": False,
                    "error": str(e)
                })
        
        # Phase 2: Four-Way Comparison Data Collection
        print("\nüîÑ PHASE 2: Four-Way Comparison Data Collection")
        print("-" * 60)
        
        for i, url in enumerate(four_way_urls, 1):
            print(f"\nüìä Collecting data from four-way comparison {i}/{len(four_way_urls)}: {url}")
            try:
                comparison_data = await self.collect_four_way_data(url)
                self.collected_data["four_way_comparisons"].append(comparison_data)
                
                print(f"   ‚úÖ Success: {comparison_data.get('success', False)}")
                print(f"   üìà Data Quality: {comparison_data.get('data_quality_score', 0):.1f}%")
                print(f"   üè¢ Products Found: {comparison_data.get('products_found', 0)}")
                print(f"   üìä Ratings Extracted: {comparison_data.get('ratings_extracted', 0)}")
                
            except Exception as e:
                print(f"   ‚ùå Error: {str(e)}")
                self.collected_data["four_way_comparisons"].append({
                    "url": url,
                    "success": False,
                    "error": str(e)
                })
        
        # Phase 3: AI Summary Extraction
        print("\nü§ñ PHASE 3: AI-Generated Summary Extraction")
        print("-" * 60)
        
        for i, url in enumerate(head_to_head_urls[:2], 1):  # Test first 2 URLs
            print(f"\nü§ñ Extracting AI summaries {i}/2: {url}")
            try:
                ai_data = await self.extract_ai_summaries(url)
                self.collected_data["ai_summaries"].append(ai_data)
                
                print(f"   ‚úÖ Success: {ai_data.get('success', False)}")
                print(f"   üìä Summaries Found: {ai_data.get('summaries_found', 0)}")
                print(f"   üéØ Quality Score: {ai_data.get('summary_quality_score', 0):.1f}%")
                print(f"   üí° Insights: {len(ai_data.get('competitive_insights', []))}")
                
            except Exception as e:
                print(f"   ‚ùå Error: {str(e)}")
                self.collected_data["ai_summaries"].append({
                    "url": url,
                    "success": False,
                    "error": str(e)
                })
        
        # Phase 4: Generate Competitive Intelligence Report
        print("\nüìä PHASE 4: Competitive Intelligence Analysis")
        print("-" * 60)
        
        competitive_insights = await self.generate_competitive_insights()
        self.collected_data["competitive_insights"] = competitive_insights
        
        print(f"   ‚úÖ Competitive Analysis Complete")
        print(f"   üìà Market Insights: {len(competitive_insights.get('market_insights', []))}")
        print(f"   üéØ Product Comparisons: {len(competitive_insights.get('product_comparisons', []))}")
        print(f"   üí° Strategic Recommendations: {len(competitive_insights.get('recommendations', []))}")
        
        # Generate final report
        await self.generate_final_data_collection_report()
        
    async def collect_head_to_head_data(self, url: str) -> Dict[str, Any]:
        """Collect comprehensive data from head-to-head comparison pages"""
        try:
            browser, page = await self.chimera.setup_ultimate_browser()
            
            # Navigate to the URL
            await page.goto(url, wait_until="networkidle")
            
            # Extract comprehensive comparison data
            comparison_data = await page.evaluate("""
                () => {
                    const data = {
                        url: window.location.href,
                        title: document.title,
                        timestamp: new Date().toISOString(),
                        success: true,
                        data_quality_score: 0,
                        total_data_points: 0,
                        ai_summaries_found: 0,
                        data_sections: {}
                    };
                    
                    // Extract AI-generated summaries
                    const aiSummaries = document.querySelectorAll('[data-testid="ai-summary"], .ai-summary, [class*="ai-summary"], [class*="generated-summary"]');
                    data.ai_summaries_found = aiSummaries.length;
                    data.ai_summaries = Array.from(aiSummaries).map(summary => ({
                        text: summary.textContent,
                        length: summary.textContent.length,
                        confidence: Math.min(100, summary.textContent.length / 10)
                    }));
                    
                    // Extract product information
                    const products = document.querySelectorAll('[class*="product"], [class*="comparison-item"], h1, h2');
                    data.products = Array.from(products).map(product => ({
                        name: product.textContent.trim(),
                        tag: product.tagName,
                        classes: product.className
                    })).filter(p => p.name.length > 0 && p.name.length < 100);
                    
                    // Extract ratings
                    const ratings = document.querySelectorAll('[class*="rating"], [class*="score"], [class*="star"]');
                    data.ratings = Array.from(ratings).map(rating => ({
                        text: rating.textContent,
                        classes: rating.className,
                        aria_label: rating.getAttribute('aria-label')
                    }));
                    
                    // Extract features
                    const features = document.querySelectorAll('[class*="feature"], [class*="criteria"]');
                    data.features = Array.from(features).map(feature => ({
                        text: feature.textContent,
                        classes: feature.className
                    }));
                    
                    // Extract reviews
                    const reviews = document.querySelectorAll('[class*="review"], [class*="comment"]');
                    data.reviews = Array.from(reviews).map(review => ({
                        text: review.textContent.substring(0, 200),
                        length: review.textContent.length,
                        classes: review.className
                    }));
                    
                    // Extract pricing information
                    const pricing = document.querySelectorAll('[class*="price"], [class*="cost"], [class*="pricing"]');
                    data.pricing = Array.from(pricing).map(price => ({
                        text: price.textContent,
                        classes: price.className
                    }));
                    
                    // Calculate data quality score
                    const totalElements = aiSummaries.length + products.length + ratings.length + features.length + reviews.length + pricing.length;
                    data.total_data_points = totalElements;
                    data.data_quality_score = Math.min(100, totalElements * 2);
                    
                    // Extract data sections
                    data.data_sections = {
                        ai_summaries: data.ai_summaries.length,
                        products: data.products.length,
                        ratings: data.ratings.length,
                        features: data.features.length,
                        reviews: data.reviews.length,
                        pricing: data.pricing.length
                    };
                    
                    return data;
                }
            """)
            
            await browser.close()
            return comparison_data
            
        except Exception as e:
            return {
                "url": url,
                "success": False,
                "error": str(e),
                "data_quality_score": 0,
                "total_data_points": 0,
                "ai_summaries_found": 0
            }
    
    async def collect_four_way_data(self, url: str) -> Dict[str, Any]:
        """Collect comprehensive data from four-way comparison pages"""
        try:
            browser, page = await self.chimera.setup_ultimate_browser()
            
            # Navigate to the URL
            await page.goto(url, wait_until="networkidle")
            
            # Extract four-way comparison data
            comparison_data = await page.evaluate("""
                () => {
                    const data = {
                        url: window.location.href,
                        title: document.title,
                        timestamp: new Date().toISOString(),
                        success: true,
                        data_quality_score: 0,
                        products_found: 0,
                        ratings_extracted: 0,
                        features_extracted: 0,
                        data_sections: {}
                    };
                    
                    // Extract products in comparison
                    const products = document.querySelectorAll('[class*="product"], [class*="comparison-item"], [class*="vendor"]');
                    data.products_found = products.length;
                    data.products = Array.from(products).map(product => ({
                        name: product.textContent.trim(),
                        classes: product.className,
                        aria_label: product.getAttribute('aria-label')
                    })).filter(p => p.name.length > 0 && p.name.length < 100);
                    
                    // Extract ratings and scores
                    const ratings = document.querySelectorAll('[class*="rating"], [class*="score"], [class*="star"], [aria-label*="out of"]');
                    data.ratings_extracted = ratings.length;
                    data.ratings = Array.from(ratings).map(rating => ({
                        text: rating.textContent,
                        aria_label: rating.getAttribute('aria-label'),
                        classes: rating.className
                    }));
                    
                    // Extract features and criteria
                    const features = document.querySelectorAll('[class*="feature"], [class*="criteria"], [class*="category"]');
                    data.features_extracted = features.length;
                    data.features = Array.from(features).map(feature => ({
                        text: feature.textContent,
                        classes: feature.className
                    }));
                    
                    // Extract market segments
                    const segments = document.querySelectorAll('[class*="segment"], [class*="market"], [class*="size"]');
                    data.segments = Array.from(segments).map(segment => ({
                        text: segment.textContent,
                        classes: segment.className
                    }));
                    
                    // Extract pricing information
                    const pricing = document.querySelectorAll('[class*="price"], [class*="cost"], [class*="pricing"]');
                    data.pricing = Array.from(pricing).map(price => ({
                        text: price.textContent,
                        classes: price.className
                    }));
                    
                    // Calculate data quality score
                    const totalElements = products.length + ratings.length + features.length + segments.length + pricing.length;
                    data.data_quality_score = Math.min(100, totalElements * 2);
                    
                    // Extract data sections
                    data.data_sections = {
                        products: data.products.length,
                        ratings: data.ratings.length,
                        features: data.features.length,
                        segments: data.segments.length,
                        pricing: data.pricing.length
                    };
                    
                    return data;
                }
            """)
            
            await browser.close()
            return comparison_data
            
        except Exception as e:
            return {
                "url": url,
                "success": False,
                "error": str(e),
                "data_quality_score": 0,
                "products_found": 0,
                "ratings_extracted": 0
            }
    
    async def extract_ai_summaries(self, url: str) -> Dict[str, Any]:
        """Extract AI-generated summaries with competitive insights"""
        try:
            browser, page = await self.chimera.setup_ultimate_browser()
            
            # Navigate to the URL
            await page.goto(url, wait_until="networkidle")
            
            # Extract AI summaries with competitive analysis
            summary_data = await page.evaluate("""
                () => {
                    const data = {
                        url: window.location.href,
                        timestamp: new Date().toISOString(),
                        success: true,
                        summaries_found: 0,
                        summary_quality_score: 0,
                        competitive_insights: []
                    };
                    
                    // Look for AI-generated summaries
                    const aiSummaries = document.querySelectorAll('[data-testid="ai-summary"], .ai-summary, [class*="ai-summary"], [class*="generated-summary"]');
                    data.summaries_found = aiSummaries.length;
                    
                    // Extract and analyze summary content
                    aiSummaries.forEach((summary, index) => {
                        const text = summary.textContent;
                        if (text && text.length > 50) {
                            // Analyze for competitive insights
                            const insights = {
                                index: index,
                                text: text,
                                length: text.length,
                                confidence: Math.min(100, text.length / 10),
                                competitive_scores: [],
                                feature_categories: [],
                                sentiment: "neutral"
                            };
                            
                            // Extract competitive scores (e.g., "scoring 9.2 compared to 8.7")
                            const scoreMatches = text.match(/(\d+\.?\d*)\s*(?:compared to|vs|versus)\s*(\d+\.?\d*)/gi);
                            if (scoreMatches) {
                                scoreMatches.forEach(match => {
                                    const scores = match.match(/(\d+\.?\d*)/g);
                                    if (scores && scores.length >= 2) {
                                        insights.competitive_scores.push({
                                            product_a_score: parseFloat(scores[1]),
                                            product_b_score: parseFloat(scores[0]),
                                            context: match
                                        });
                                    }
                                });
                            }
                            
                            // Identify feature categories
                            const featureKeywords = ['data visualization', 'ease of use', 'setup', 'ai', 'analytics', 'collaboration', 'integration'];
                            featureKeywords.forEach(keyword => {
                                if (text.toLowerCase().includes(keyword)) {
                                    insights.feature_categories.push(keyword);
                                }
                            });
                            
                            // Determine sentiment
                            const positiveWords = ['excel', 'better', 'superior', 'advantage', 'strong', 'excellent'];
                            const negativeWords = ['weak', 'poor', 'limited', 'disadvantage', 'lacking'];
                            
                            const positiveCount = positiveWords.filter(word => text.toLowerCase().includes(word)).length;
                            const negativeCount = negativeWords.filter(word => text.toLowerCase().includes(word)).length;
                            
                            if (positiveCount > negativeCount) {
                                insights.sentiment = "positive";
                            } else if (negativeCount > positiveCount) {
                                insights.sentiment = "negative";
                            }
                            
                            data.competitive_insights.push(insights);
                        }
                    });
                    
                    // Calculate quality score
                    data.summary_quality_score = Math.min(100, data.summaries_found * 30 + data.competitive_insights.length * 10);
                    
                    return data;
                }
            """)
            
            await browser.close()
            return summary_data
            
        except Exception as e:
            return {
                "url": url,
                "success": False,
                "error": str(e),
                "summaries_found": 0,
                "summary_quality_score": 0,
                "competitive_insights": []
            }
    
    async def generate_competitive_insights(self) -> Dict[str, Any]:
        """Generate competitive intelligence insights from collected data"""
        try:
            insights = {
                "timestamp": datetime.now().isoformat(),
                "market_insights": [],
                "product_comparisons": [],
                "recommendations": [],
                "data_quality_summary": {}
            }
            
            # Analyze head-to-head comparisons
            successful_comparisons = [c for c in self.collected_data["head_to_head_comparisons"] if c.get("success", False)]
            insights["data_quality_summary"]["head_to_head_success_rate"] = len(successful_comparisons) / len(self.collected_data["head_to_head_comparisons"]) * 100
            
            # Analyze four-way comparisons
            successful_four_way = [c for c in self.collected_data["four_way_comparisons"] if c.get("success", False)]
            insights["data_quality_summary"]["four_way_success_rate"] = len(successful_four_way) / len(self.collected_data["four_way_comparisons"]) * 100
            
            # Analyze AI summaries
            successful_ai = [a for a in self.collected_data["ai_summaries"] if a.get("success", False)]
            insights["data_quality_summary"]["ai_summary_success_rate"] = len(successful_ai) / len(self.collected_data["ai_summaries"]) * 100
            
            # Generate market insights
            total_products = []
            for c in successful_comparisons:
                if c.get("products"):
                    total_products.extend(c.get("products", []))
            
            insights["market_insights"].append({
                "insight": f"Analyzed {len(total_products)} products across {len(successful_comparisons)} comparisons",
                "confidence": 85.0
            })
            
            # Generate product comparisons
            for comparison in successful_comparisons:
                if comparison.get("products"):
                    insights["product_comparisons"].append({
                        "url": comparison["url"],
                        "products_analyzed": len(comparison["products"]),
                        "data_quality": comparison.get("data_quality_score", 0)
                    })
            
            # Generate recommendations
            insights["recommendations"].append({
                "recommendation": "Focus on AI-generated summaries for competitive intelligence",
                "rationale": "AI summaries provide synthesized insights from user reviews",
                "priority": "high"
            })
            
            insights["recommendations"].append({
                "recommendation": "Expand four-way comparison analysis",
                "rationale": "Four-way comparisons provide comprehensive market positioning",
                "priority": "medium"
            })
            
            return insights
            
        except Exception as e:
            return {
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
                "market_insights": [],
                "product_comparisons": [],
                "recommendations": []
            }
    
    async def generate_final_data_collection_report(self):
        """Generate final data collection report"""
        print("\nüìã FINAL DATA COLLECTION REPORT")
        print("=" * 80)
        
        # Calculate success rates
        head_to_head_success = sum(1 for c in self.collected_data["head_to_head_comparisons"] if c.get("success", False)) / len(self.collected_data["head_to_head_comparisons"]) * 100
        four_way_success = sum(1 for c in self.collected_data["four_way_comparisons"] if c.get("success", False)) / len(self.collected_data["four_way_comparisons"]) * 100
        ai_summary_success = sum(1 for a in self.collected_data["ai_summaries"] if a.get("success", False)) / len(self.collected_data["ai_summaries"]) * 100
        
        # Calculate total data points
        total_data_points = sum(c.get("total_data_points", 0) for c in self.collected_data["head_to_head_comparisons"] if c.get("success", False))
        total_data_points += sum(c.get("products_found", 0) + c.get("ratings_extracted", 0) for c in self.collected_data["four_way_comparisons"] if c.get("success", False))
        
        # Calculate average data quality
        avg_quality = 0
        quality_scores = []
        for c in self.collected_data["head_to_head_comparisons"] + self.collected_data["four_way_comparisons"]:
            if c.get("success", False) and c.get("data_quality_score", 0) > 0:
                quality_scores.append(c.get("data_quality_score", 0))
        
        if quality_scores:
            avg_quality = sum(quality_scores) / len(quality_scores)
        
        self.collected_data["summary"] = {
            "head_to_head_success_rate": head_to_head_success,
            "four_way_success_rate": four_way_success,
            "ai_summary_success_rate": ai_summary_success,
            "total_data_points_collected": total_data_points,
            "average_data_quality": avg_quality,
            "total_comparisons_analyzed": len(self.collected_data["head_to_head_comparisons"]) + len(self.collected_data["four_way_comparisons"]),
            "ai_summaries_extracted": sum(a.get("summaries_found", 0) for a in self.collected_data["ai_summaries"] if a.get("success", False))
        }
        
        # Print summary
        print(f"üìä DATA COLLECTION RESULTS:")
        print(f"   Head-to-Head Success Rate: {head_to_head_success:.1f}%")
        print(f"   Four-Way Success Rate: {four_way_success:.1f}%")
        print(f"   AI Summary Success Rate: {ai_summary_success:.1f}%")
        print(f"   Total Data Points Collected: {total_data_points}")
        print(f"   Average Data Quality: {avg_quality:.1f}%")
        print(f"   AI Summaries Extracted: {self.collected_data['summary']['ai_summaries_extracted']}")
        
        # Print detailed results
        print(f"\nüìã DETAILED RESULTS:")
        for i, comparison in enumerate(self.collected_data["head_to_head_comparisons"], 1):
            status = "‚úÖ" if comparison.get("success", False) else "‚ùå"
            print(f"   {status} Head-to-Head {i}: {comparison.get('data_quality_score', 0):.1f}% quality, {comparison.get('total_data_points', 0)} data points")
        
        for i, comparison in enumerate(self.collected_data["four_way_comparisons"], 1):
            status = "‚úÖ" if comparison.get("success", False) else "‚ùå"
            print(f"   {status} Four-Way {i}: {comparison.get('data_quality_score', 0):.1f}% quality, {comparison.get('products_found', 0)} products")
        
        for i, ai_data in enumerate(self.collected_data["ai_summaries"], 1):
            status = "‚úÖ" if ai_data.get("success", False) else "‚ùå"
            print(f"   {status} AI Summary {i}: {ai_data.get('summaries_found', 0)} summaries, {ai_data.get('summary_quality_score', 0):.1f}% quality")
        
        # Save comprehensive data
        report_file = f"actual_data_collection_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(self.collected_data, f, indent=2)
        
        print(f"\nüíæ Complete data collection report saved to: {report_file}")
        
        # Final assessment
        overall_success = (head_to_head_success + four_way_success + ai_summary_success) / 3
        if overall_success >= 80:
            print(f"\nüéâ DATA COLLECTION SUCCESSFUL!")
            print(f"   The scraper successfully collected real data from G2.com comparison pages")
            print(f"   Proving scraping capabilities as described in implementation guides")
            print(f"   Overall Success Rate: {overall_success:.1f}%")
        else:
            print(f"\n‚ö†Ô∏è  PARTIAL DATA COLLECTION SUCCESS")
            print(f"   Some data collection failed - review and improve scraping methods")
            print(f"   Overall Success Rate: {overall_success:.1f}%")

async def main():
    """Main data collection execution"""
    tester = ActualDataCollectionTester()
    await tester.run_complete_data_collection()

if __name__ == "__main__":
    asyncio.run(main())
